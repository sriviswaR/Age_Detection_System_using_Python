{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Aq91uKBpAKNp"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import Sequence\n",
        "\n",
        "class UTKFaceDataGenerator(Sequence):\n",
        "    def __init__(self, img_folder, img_list, labels, batch_size=32, img_size=(224, 224), shuffle=True):\n",
        "        self.img_folder = img_folder\n",
        "        self.img_list = img_list\n",
        "        self.labels = labels\n",
        "        self.batch_size = batch_size\n",
        "        self.img_size = img_size\n",
        "        self.shuffle = shuffle\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.floor(len(self.img_list) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        indices = self.indices[index * self.batch_size:(index + 1) * self.batch_size]\n",
        "        batch_img_list = [self.img_list[k] for k in indices]\n",
        "        batch_labels = [self.labels[k] for k in indices]\n",
        "\n",
        "        X, y = self.__data_generation(batch_img_list, batch_labels)\n",
        "        return X, y\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        self.indices = np.arange(len(self.img_list))\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.indices)\n",
        "\n",
        "    def __data_generation(self, batch_img_list, batch_labels):\n",
        "        X = np.empty((self.batch_size, *self.img_size, 3))\n",
        "        y = np.empty((self.batch_size), dtype=int)\n",
        "\n",
        "        for i, img_name in enumerate(batch_img_list):\n",
        "            img = cv2.imread(os.path.join(self.img_folder, img_name))\n",
        "            img = cv2.resize(img, self.img_size)\n",
        "            img = img / 255.0\n",
        "            X[i,] = img\n",
        "            y[i] = batch_labels[i]\n",
        "\n",
        "        return X, y\n",
        "\n",
        "# Define paths\n",
        "data_path = 'utk/utkcropped/utkcropped'  # Update this path\n",
        "\n",
        "# Prepare data lists\n",
        "img_list = []\n",
        "ages = []\n",
        "\n",
        "# Load image names and labels\n",
        "for i, img_name in enumerate(os.listdir(data_path)):\n",
        "    if i >= 10000:\n",
        "        break\n",
        "    img_list.append(img_name)\n",
        "    age = int(img_name.split('_')[0])\n",
        "    ages.append(age)\n",
        "\n",
        "# Split data into training and testing\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_img_list, test_img_list, train_labels, test_labels = train_test_split(img_list, ages, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create data generators\n",
        "batch_size = 32\n",
        "train_generator = UTKFaceDataGenerator(data_path, train_img_list, train_labels, batch_size=batch_size)\n",
        "test_generator = UTKFaceDataGenerator(data_path, test_img_list, test_labels, batch_size=batch_size, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_wo5e6NaAdR_",
        "outputId": "e8564ff3-c032-483f-843b-1d8a94691f47"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-05-21 14:42:38.885639: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-05-21 14:42:38.919259: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-05-21 14:42:38.919495: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-05-21 14:42:38.921191: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-05-21 14:42:38.921366: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-05-21 14:42:38.921523: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-05-21 14:42:38.969027: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-05-21 14:42:38.969280: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-05-21 14:42:38.969577: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-05-21 14:42:38.969718: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2285 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, 224, 224, 3)]        0         []                            \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)             (None, 224, 224, 32)         896       ['input_1[0][0]']             \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2  (None, 112, 112, 32)         0         ['conv2d[0][0]']              \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)           (None, 112, 112, 32)         1056      ['max_pooling2d[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)           (None, 112, 112, 32)         9248      ['max_pooling2d[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)           (None, 112, 112, 32)         25632     ['max_pooling2d[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization (Batch  (None, 112, 112, 32)         128       ['conv2d_1[0][0]']            \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_1 (Bat  (None, 112, 112, 32)         128       ['conv2d_2[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_2 (Bat  (None, 112, 112, 32)         128       ['conv2d_3[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation (Activation)     (None, 112, 112, 32)         0         ['batch_normalization[0][0]'] \n",
            "                                                                                                  \n",
            " activation_1 (Activation)   (None, 112, 112, 32)         0         ['batch_normalization_1[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " activation_2 (Activation)   (None, 112, 112, 32)         0         ['batch_normalization_2[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " add (Add)                   (None, 112, 112, 32)         0         ['activation[0][0]',          \n",
            "                                                                     'activation_1[0][0]',        \n",
            "                                                                     'activation_2[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)           (None, 112, 112, 1)          33        ['add[0][0]']                 \n",
            "                                                                                                  \n",
            " multiply (Multiply)         (None, 112, 112, 32)         0         ['max_pooling2d[0][0]',       \n",
            "                                                                     'conv2d_4[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)           (None, 112, 112, 64)         18496     ['multiply[0][0]']            \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPoolin  (None, 56, 56, 64)           0         ['conv2d_5[0][0]']            \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)           (None, 56, 56, 64)           4160      ['max_pooling2d_1[0][0]']     \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)           (None, 56, 56, 64)           36928     ['max_pooling2d_1[0][0]']     \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)           (None, 56, 56, 64)           102464    ['max_pooling2d_1[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_3 (Bat  (None, 56, 56, 64)           256       ['conv2d_6[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_4 (Bat  (None, 56, 56, 64)           256       ['conv2d_7[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_5 (Bat  (None, 56, 56, 64)           256       ['conv2d_8[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_3 (Activation)   (None, 56, 56, 64)           0         ['batch_normalization_3[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " activation_4 (Activation)   (None, 56, 56, 64)           0         ['batch_normalization_4[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " activation_5 (Activation)   (None, 56, 56, 64)           0         ['batch_normalization_5[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " add_1 (Add)                 (None, 56, 56, 64)           0         ['activation_3[0][0]',        \n",
            "                                                                     'activation_4[0][0]',        \n",
            "                                                                     'activation_5[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)           (None, 56, 56, 1)            65        ['add_1[0][0]']               \n",
            "                                                                                                  \n",
            " multiply_1 (Multiply)       (None, 56, 56, 64)           0         ['max_pooling2d_1[0][0]',     \n",
            "                                                                     'conv2d_9[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)          (None, 56, 56, 128)          73856     ['multiply_1[0][0]']          \n",
            "                                                                                                  \n",
            " max_pooling2d_2 (MaxPoolin  (None, 28, 28, 128)          0         ['conv2d_10[0][0]']           \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)          (None, 28, 28, 128)          16512     ['max_pooling2d_2[0][0]']     \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)          (None, 28, 28, 128)          147584    ['max_pooling2d_2[0][0]']     \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)          (None, 28, 28, 128)          409728    ['max_pooling2d_2[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_6 (Bat  (None, 28, 28, 128)          512       ['conv2d_11[0][0]']           \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_7 (Bat  (None, 28, 28, 128)          512       ['conv2d_12[0][0]']           \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_8 (Bat  (None, 28, 28, 128)          512       ['conv2d_13[0][0]']           \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_6 (Activation)   (None, 28, 28, 128)          0         ['batch_normalization_6[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " activation_7 (Activation)   (None, 28, 28, 128)          0         ['batch_normalization_7[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " activation_8 (Activation)   (None, 28, 28, 128)          0         ['batch_normalization_8[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " add_2 (Add)                 (None, 28, 28, 128)          0         ['activation_6[0][0]',        \n",
            "                                                                     'activation_7[0][0]',        \n",
            "                                                                     'activation_8[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)          (None, 28, 28, 1)            129       ['add_2[0][0]']               \n",
            "                                                                                                  \n",
            " multiply_2 (Multiply)       (None, 28, 28, 128)          0         ['max_pooling2d_2[0][0]',     \n",
            "                                                                     'conv2d_14[0][0]']           \n",
            "                                                                                                  \n",
            " global_average_pooling2d (  (None, 128)                  0         ['multiply_2[0][0]']          \n",
            " GlobalAveragePooling2D)                                                                          \n",
            "                                                                                                  \n",
            " dense (Dense)               (None, 128)                  16512     ['global_average_pooling2d[0][\n",
            "                                                                    0]']                          \n",
            "                                                                                                  \n",
            " dense_1 (Dense)             (None, 1)                    129       ['dense[0][0]']               \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 866116 (3.30 MB)\n",
            "Trainable params: 864772 (3.30 MB)\n",
            "Non-trainable params: 1344 (5.25 KB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, GlobalAveragePooling2D, Multiply, Add, Activation, BatchNormalization\n",
        "\n",
        "# Define the attention block\n",
        "def attention_block(inputs, filters):\n",
        "    g1 = Conv2D(filters, (1, 1), padding='same')(inputs)\n",
        "    g1 = BatchNormalization()(g1)\n",
        "    g1 = Activation('relu')(g1)\n",
        "\n",
        "    g2 = Conv2D(filters, (3, 3), padding='same')(inputs)\n",
        "    g2 = BatchNormalization()(g2)\n",
        "    g2 = Activation('relu')(g2)\n",
        "\n",
        "    g3 = Conv2D(filters, (5, 5), padding='same')(inputs)\n",
        "    g3 = BatchNormalization()(g3)\n",
        "    g3 = Activation('relu')(g3)\n",
        "\n",
        "    attn = Add()([g1, g2, g3])\n",
        "    attn = Conv2D(1, (1, 1), padding='valid', activation='sigmoid')(attn)\n",
        "    attn = Multiply()([inputs, attn])\n",
        "\n",
        "    return attn\n",
        "\n",
        "# Build the model\n",
        "input_shape = (224, 224, 3)\n",
        "inputs = Input(shape=input_shape)\n",
        "\n",
        "x = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
        "x = MaxPooling2D((2, 2))(x)\n",
        "x = attention_block(x, 32)\n",
        "\n",
        "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "x = MaxPooling2D((2, 2))(x)\n",
        "x = attention_block(x, 64)\n",
        "\n",
        "x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
        "x = MaxPooling2D((2, 2))(x)\n",
        "x = attention_block(x, 128)\n",
        "\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "outputs = Dense(1)(x)  # For regression (age prediction)\n",
        "\n",
        "model = Model(inputs, outputs)\n",
        "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
        "\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wtn1UE5GFg6x",
        "outputId": "62d4a5de-ec59-4a90-8e0d-e49c037fb807"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-05-21 14:42:46.001937: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8904\n",
            "2024-05-21 14:42:50.472644: I external/local_xla/xla/service/service.cc:168] XLA service 0x872bd60 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2024-05-21 14:42:50.472665: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3050 Laptop GPU, Compute Capability 8.6\n",
            "2024-05-21 14:42:50.475948: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "I0000 00:00:1716282770.538213   37503 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "250/250 [==============================] - 61s 163ms/step - loss: 416.0507 - mae: 15.4607 - val_loss: 397.0396 - val_mae: 16.0450\n",
            "Epoch 2/20\n",
            "250/250 [==============================] - 37s 149ms/step - loss: 285.5162 - mae: 13.0588 - val_loss: 1264.7233 - val_mae: 30.8093\n",
            "Epoch 3/20\n",
            "250/250 [==============================] - 37s 150ms/step - loss: 255.1515 - mae: 12.3448 - val_loss: 647.1624 - val_mae: 22.0897\n",
            "Epoch 4/20\n",
            "250/250 [==============================] - 37s 150ms/step - loss: 233.8052 - mae: 11.7371 - val_loss: 270.0988 - val_mae: 12.7434\n",
            "Epoch 5/20\n",
            "250/250 [==============================] - 38s 150ms/step - loss: 219.8386 - mae: 11.4061 - val_loss: 621.9278 - val_mae: 19.2196\n",
            "Epoch 6/20\n",
            "250/250 [==============================] - 38s 151ms/step - loss: 215.2880 - mae: 11.2743 - val_loss: 1091.2350 - val_mae: 27.9640\n",
            "Epoch 7/20\n",
            "250/250 [==============================] - 38s 151ms/step - loss: 219.0521 - mae: 11.3203 - val_loss: 938.4686 - val_mae: 24.6856\n",
            "Epoch 8/20\n",
            "250/250 [==============================] - 48s 193ms/step - loss: 209.3326 - mae: 11.1014 - val_loss: 944.7045 - val_mae: 26.1823\n",
            "Epoch 9/20\n",
            "250/250 [==============================] - 45s 181ms/step - loss: 201.3705 - mae: 10.8576 - val_loss: 342.8597 - val_mae: 15.3064\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "history = model.fit(train_generator, epochs=20, validation_data=test_generator, callbacks=[early_stopping])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4DencHjpFkd-",
        "outputId": "e1dbbe98-df4c-488f-846b-10f1b412b48d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "62/62 [==============================] - 3s 45ms/step - loss: 270.0988 - mae: 12.7434\n",
            "Test Mean Absolute Error: 12.743355751037598\n"
          ]
        }
      ],
      "source": [
        "test_loss, test_mae = model.evaluate(test_generator)\n",
        "print(f'Test Mean Absolute Error: {test_mae}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Ag4_Y2yoHOyq"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/eragon/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ],
      "source": [
        "model.save('age_detection_model_5000_images.h5')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpvhbeuuom/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpvhbeuuom/assets\n",
            "2024-05-21 16:57:59.609924: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
            "2024-05-21 16:57:59.609947: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
            "2024-05-21 16:57:59.610364: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmpvhbeuuom\n",
            "2024-05-21 16:57:59.613959: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
            "2024-05-21 16:57:59.613972: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /tmp/tmpvhbeuuom\n",
            "2024-05-21 16:57:59.623529: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:388] MLIR V1 optimization pass is not enabled\n",
            "2024-05-21 16:57:59.626935: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
            "2024-05-21 16:57:59.769000: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /tmp/tmpvhbeuuom\n",
            "2024-05-21 16:57:59.807278: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 196913 microseconds.\n",
            "2024-05-21 16:57:59.860088: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
            "Summary on the non-converted ops:\n",
            "---------------------------------\n",
            " * Accepted dialects: tfl, builtin, func\n",
            " * Non-Converted Ops: 35, Total Ops 71, % non-converted = 49.30 %\n",
            " * 35 ARITH ops\n",
            "\n",
            "- arith.constant:   35 occurrences  (f32: 34, i32: 1)\n",
            "\n",
            "\n",
            "\n",
            "  (f32: 6)\n",
            "  (f32: 15)\n",
            "  (f32: 2)\n",
            "  (f32: 3)\n",
            "  (f32: 3)\n",
            "  (f32: 1)\n",
            "  (f32: 3)\n"
          ]
        }
      ],
      "source": [
        "model = load_model('age_detection_model_5000_images.h5')\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "\n",
        "with open('age_detection_model.tflite', 'wb') as f:\n",
        "    f.write(tflite_model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "\n",
        "# Load the TFLite model and allocate tensors\n",
        "interpreter = tf.lite.Interpreter(model_path='age_detection_model.tflite')\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "# Get input and output tensors\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "def preprocess_image(image):\n",
        "    img = cv2.resize(image, (224, 224))\n",
        "    img = img.astype(np.float32)\n",
        "    img = img / 255.0\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "    return img"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "FOR FACE DETECTION/TRACKING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the Haar Cascade face detector\n",
        "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n",
            "QObject::moveToThread: Current thread (0x1193b860) is not the object's thread (0x16651b90).\n",
            "Cannot move to target thread (0x1193b860)\n",
            "\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[13], line 32\u001b[0m\n\u001b[1;32m     29\u001b[0m interpreter\u001b[38;5;241m.\u001b[39mset_tensor(input_details[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m'\u001b[39m], input_data)\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Run the interpreter\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m interpreter\u001b[38;5;241m.\u001b[39minvoke()\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Get the predicted age\u001b[39;00m\n\u001b[1;32m     35\u001b[0m output_data \u001b[38;5;241m=\u001b[39m interpreter\u001b[38;5;241m.\u001b[39mget_tensor(output_details[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/lite/python/interpreter.py:941\u001b[0m, in \u001b[0;36mInterpreter.invoke\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    929\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Invoke the interpreter.\u001b[39;00m\n\u001b[1;32m    930\u001b[0m \n\u001b[1;32m    931\u001b[0m \u001b[38;5;124;03mBe sure to set the input sizes, allocate tensors and fill values before\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    938\u001b[0m \u001b[38;5;124;03m  ValueError: When the underlying interpreter fails raise ValueError.\u001b[39;00m\n\u001b[1;32m    939\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    940\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_safe()\n\u001b[0;32m--> 941\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interpreter\u001b[38;5;241m.\u001b[39mInvoke()\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Initialize webcam\n",
        "cap = cv2.VideoCapture(0)\n",
        "\n",
        "while True:\n",
        "    # Capture frame-by-frame\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # Convert frame to grayscale for face detection\n",
        "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Detect faces in the frame\n",
        "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
        "\n",
        "    if len(faces) == 0:\n",
        "        # No face detected, predict age as 0\n",
        "        age_prediction = 0\n",
        "    else:\n",
        "        for (x, y, w, h) in faces:\n",
        "            # Draw a red rectangle around the detected face\n",
        "            cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 0, 255), 2)\n",
        "\n",
        "            # Preprocess the face region\n",
        "            face = frame[y:y+h, x:x+w]\n",
        "            input_data = preprocess_image(face)\n",
        "\n",
        "            # Set the tensor to point to the input data to be inferred\n",
        "            interpreter.set_tensor(input_details[0]['index'], input_data)\n",
        "\n",
        "            # Run the interpreter\n",
        "            interpreter.invoke()\n",
        "\n",
        "            # Get the predicted age\n",
        "            output_data = interpreter.get_tensor(output_details[0]['index'])\n",
        "            age_prediction = output_data[0][0]\n",
        "\n",
        "            # Display the results\n",
        "            cv2.putText(frame, f'Predicted Age: {int(age_prediction)}', (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
        "\n",
        "    # Show the frame with the face rectangle and age prediction\n",
        "    cv2.imshow('Age Detection', frame)\n",
        "\n",
        "    # Press 'q' to quit the video stream\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "# When everything is done, release the capture and close windows\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
